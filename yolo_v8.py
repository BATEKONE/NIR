from ultralytics import YOLO
import gradio as gr
from PIL import Image
import cv2
import os
import torch

print("[INFO] CUDA –¥–æ—Å—Ç—É–ø–µ–Ω:", torch.cuda.is_available())
print("[INFO] –¢–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")

# –ü—É—Ç–∏
MODEL_PATH = "runs/detect/train/weights/best.pt"
DATA_YAML_PATH = "helmet_yolo_dataset/data.yaml"
YOLO_ARCH = "yolov8s.pt"  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ yolov8s.pt –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
if not os.path.exists(MODEL_PATH):
    print("[INFO] –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ YOLOv8...")
    model = YOLO(YOLO_ARCH)
    model.train(data=DATA_YAML_PATH, epochs=30, imgsz=640, batch=16, device='cuda', workers=0)
    trained_model = model
    print("[INFO] –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
else:
    print("[INFO] –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å...")
    trained_model = YOLO(MODEL_PATH)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
def predict(image):
    img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    results = trained_model(img)[0]
    annotated_img = results.plot()
    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)

    num_no_helmet = sum(int(box.cls) == 1 for box in results.boxes)
    violation_text = f"–ù–∞—Ä—É—à–µ–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {num_no_helmet}" if num_no_helmet else "–ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"

    return Image.fromarray(annotated_img), violation_text

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio
with gr.Blocks() as demo:
    gr.Markdown("# ü™ñ –°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–æ—Ç–æ—Ü–∏–∫–ª–∏—Å—Ç–æ–≤ –±–µ–∑ —à–ª–µ–º–∞ (YOLOv8)")

    with gr.Row():
        input_image = gr.Image(label="–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        output_image = gr.Image(label="–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è")

    violation_output = gr.Textbox(label="–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏")
    submit_btn = gr.Button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

    submit_btn.click(fn=predict, inputs=input_image, outputs=[output_image, violation_output])

    if os.path.exists("test"):
        examples = [os.path.join("test", f) for f in os.listdir("test") if f.lower().endswith((".jpg", ".png"))][:3]
        gr.Examples(examples=examples, inputs=input_image)

demo.launch()